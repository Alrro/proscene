#summary Wiki page containing all the project news.

=20/04/2011 Release of *Proscene v-1.1.0-alpha1 (a.k.a. v-1.0.6)*=

This is the first alpha release of the next version of *proscene* targeted at testers and early enthusiasts that wish to give us some feedback (download it [http://proscene.googlecode.com/files/proscene-1.0.6.zip here]). Development has been focused in the following arenas:

 * Works with the latest [http://processing.org/ Processing] version (1.5). The current stable version of *proscene (1.0.0)* should do it too.
 * Fixes a bug in the `Camera.sphereIsVisible` test needed to properly implement view-frustum-culling.
 * *Off-screen-rendering* has been greatly improved which means *proscene* examples with multiple viewers running in a single skecth no longer require the *napplet* dependency.
 * Generic suppport for [http://en.wikipedia.org/wiki/Human_interface_device Human Interface Devices] has been implemented.

The main goal of this release has been to add support for Human Interface Devices (HID) with six (or less) [http://en.wikipedia.org/wiki/6DOF degrees-of-freedom] to control both the camera and any interactive frame attached to the *scene*. This has been done through the new *HIDevice* class. An *HIDevice* object can be of one of two types: *RELATIVE* or *ABSOLUTE*:

 * A *RELATIVE HIDevice* (default configuration) has a neutral position that the device holds when it is not being manipulated. Examples of such devices are the [http://en.wikipedia.org/wiki/Space_navigator 3d space navigator] and the [http://en.wikipedia.org/wiki/Joystick joystick].
 * An *ABSOLUTE HIDevice* has no such neutral position. Examples of ABSOLUTE devices are the [http://en.wikipedia.org/wiki/Wii wii] and the [http://en.wikipedia.org/wiki/Kinect kinect].

==How to use an *HIDevice*?==

Suppose that we wish to control our camera and some objects in our *scene* using a [http://en.wikipedia.org/wiki/6DOF 6-DOF] device such the [http://en.wikipedia.org/wiki/Space_navigator 3d space navigator]. We do it by declaring an *HIDevice* and "feed" it with the output generated by the physical device reported by a third party hardware controller. Once we instantiate an *HIDevice*, say `dev`, we can cycle to the predefined camera and frame configurations calling `dev.nextCameraMode()` and `dev.nextIFrameMode()`, respectively.

To instantiate and define an *HIDevice* we have the following two options (in the code snippets below *note* that the `slider*pos` and the `slider*rot` objects belong to the third party library actually controlling the hardware):

===Option 1: Declare your own HIDevice and add a feed handler ===

{{{
void setup() {
  ...
  scene = new Scene(this);//declare the scene, which is the main Proscene object
  dev = new HIDevice(scene);//declare a RELATIVE mode HIDevice
  dev.addHandler(this, "feed");//add the feed defined below
  //Define the translation sensitivities
  //(0 will disable the translation, a negative value will reverse its direction)
  dev.setTranslationSensitivity(0.01f, 0.01f, 0.01f);
  //Define the translation sensitivities
  //(0 will disable the rotation, a negative value will reverse its orientation)
  dev.setRotationSensitivity(0.0001f, 0.0001f, 0.0001f);
  scene.addDevice(dev);
}
//The feed handler function should look like the following:
void feed(HIDevice d) {
  //enable the three translations
  //again, 0 will disable the translation, a negative value will reverse its direction
  //to produce a different mapping between the device axes and the different scene coordinates systems' axes
  //(referred to in proscene as Frames) simply exchange the order of the slider*pos parameters at will.
  d.feedTranslation(sliderXpos.getValue(), sliderYpos.getValue(), sliderZpos.getValue());
  //enable the three rotations
  //again, 0 will disable the rotation, a negative value will reverse its orientation
  //to produce a different mapping between the device axes and the different scene frames'
  //axes simply exchange the order of the slider*pos parameters at will.
  d.feedRotation(sliderXrot.getValue(), sliderYrot.getValue(), sliderZrot.getValue());
}
}}}

===Option 2: Declare your own HIDevice derived class and override the feeds===

The following code will handle the device exactly as in the previous option.

{{{
void setup() {
  ...
  scene = new Scene(this);//declare the scene, which is the main Proscene object
  //declare your own HIDevice derived class
  dev = new HIDevice(scene) {
    //if one of the feeds is not overridden the correspondent translation/rotation would be disabled 
    public float feedXTranslation() {
      return sliderXpos.getValue();
    }
    public float feedYTranslation() {
      return sliderYpos.getValue();
    }
    public float feedZTranslation() {
      return sliderZpos.getValue();
    }
    public float feedXRotation() {
      return sliderXrot.getValue();
    }
    public float feedYRotation() {
      return sliderYrot.getValue();
    }
    public float feedZRotation() {
      return sliderZrot.getValue();
    }
  };
  //Define the translation sensitivities
  //(0 will disable the translation, a negative value will reverse its direction)
  dev.setTranslationSensitivity(0.01f, 0.01f, 0.01f);
  //Define the translation sensitivities
  //(0 will disable the rotation, a negative value will reverse its orientation)
  dev.setRotationSensitivity(0.0001f, 0.0001f, 0.0001f);
  scene.addDevice(dev);
}
}}}

==Observations:==

 # *Proscene* does not handle the device directly. This should be achieved  with a third party library such [http://www.creativecomputing.cc/p5libs/procontroll/ procontroll].
 # An *HIDevice* implements some default configurations to manipulate the camera and a given interactive frame. A third party configuration can easily be implemented too (see the *HIDevice* API for details). *If you implement your own configuration and wish to share please let us know. If you want us to implement a new one, let us know it too :)*
 # There are three new examples that illustrate how to instantiate and use an *HIDevice*: *!SpaceNavigator*, *HIDeviceSingleViewer*, and *HIDeviceMultiViewer*. The three examples require a space navigator and while the first one should make it to the final release the latter two are provided only for testing purposes.
 # These three examples have been tested in Ubuntu and Windows using *procontroll* but they only work in Windows. This has to do with a *procontroll* issue (I already contacted its developers to try to solve it). Testing them in Mac still requires to be done. *Feedback is more than welcome*!
 # If you implement support for another device *please let us know*. For instance we'd love to see support for the kinect in the near future. We just don't have one to play around at the time ;)

=14/12/2010 Release of *Proscene v-1.0.0*=

Our Christmas mushroom is out for you to grab it! We are pleased to announce the immediate availability of proscene v-1.0.0. Changelog:

  # *Keyboard shortcuts and camera profiles customization*. Keyboard shortcuts which define global actions (such as drawing of the world axis), and mouse bindings which define how camera actions are binded to the mouse, are fully customizable. Their default behavior should cover most user needs out there though. See the new example [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/CameraCustomization/applet/index.html CameraCustomization].
  # *New animation framework.* The framework comprises three animation mechanisms to define how your scene evolves over time:
    # *Overriding the animate() method.* In this case, once you declare a Scene derived class, you should implement _animate()_ which defines how your scene objects evolve over time. See the new example [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/Animation/applet/index.html Animation].
    # *External animation handler registration.* You can also declare an external animation method and then register it at the Scene with _addAnimationHandler(Object, String)_. That method should return {{{void}}} and have one single {{{Scene}}} parameter. See the new example [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/AnimationHandler/applet/index.html AnimationHandler].
    # *By querying the state of the animatedFrameWasTriggered variable.* During the drawing loop, the variable _animatedFrameWasTriggered_ is set to {{{true}}} each time an animated frame is triggered (or it is set to {{{false}}} otherwise), which is useful to notify the outside world when an animation event occurs. See the example [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/Flock/applet/index.html Flock] which has been ported to the new animation framework using this technique.
  # *New off-screen rendering mode support*. Off-screen rendering mode allows to map your scene contents to a texture and then you can do whatever you want with it. Check the new example [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/BasicUseOffscreen/applet/index.html BasicUseOffscreen].
  # *New and improved examples* which illustrates many aspects of the library. New examples are: [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/Animation/applet/index.html Animation], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/AnimationHandler/applet/index.html AnimationHandler], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/BasicUseOffscreen/applet/index.html BasicUseOffscreen], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/CameraCustomization/applet/index.html CameraCustomization] and [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/Scramble/applet/index.html Scramble]. Improved examples are: [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/CameraInterpolation/applet/index.html CameraInterpolation], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/MouseGrabbers/applet/index.html MouseGrabbers] and [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-1.0.0/demos/Flock/applet/index.html Flock].

Many thanks to [http://codeanticode.wordpress.com Andres Colubri] for all his contributions to the project which includes, among many, off-screen rendering mode. Many thanks also to Alejandro Duarte for his cool Scramble demo. Many thanks also to other contributors, testers and followers!

=18/07/2010 Release of *Proscene v-0.9.0*=

Version 0.9.0 of *Proscene* is out. Changelog:

 * New examples: [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/Flock/applet/index.html Flock], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/StandardCamera/applet/index.html StandardCamera], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/ThirdPersonCamera/applet/index.html ThirdPersonCamera] and [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/ViewFrustumCulling/applet/index.html ViewFrustumCulling].
 * New scene external draw handler registration (see the Scene documentation for details).
 * New analytical computation of the frustum planes equations which enables view frustum culling against the proscene camera.
 * New THIRD_PERSON camera mode. How does it work?
   * Simply add an _!InteractiveAvatarFrame_ (which is an specialization of an _Avatar_) to your scene: call {{{scene.setInteractiveFrame(myInteractiveAvatarFrame)}}} (see the example [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/ThirdPersonCamera/applet/index.html ThirdPersonCamera]) or  {{{scene.setAvatar(myAvatar)}}} (see the example [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/Flock/applet/index.html Flock]).
   * Then just call {{{scene.setCameraMode(CameraMode.THIRD_PERSON)}}} and the camera will follow your _!InteractiveAvatarFrame_ (which is controlled using the mouse).
 * New registration of the keyboard and mouse handlers which provides tighter integration with processing. It also means that proscene enabled sketches comprise even less code.
 * Code polishing.
 * Developed and fully tested in *Processing-1.2.1* under x86_64 GNU/Linux (Kubuntu-10.04).

Many thanks to [http://github.com/acsmith/napplet "adamcsmitty"] and to [http://www.lagers.org.uk/ Peter Lagger] for their suggestions regarding how to handle multiple viewers in proscene. *Note* that the new [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/StandardCamera/applet/index.html StandardCamera] and [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/ViewFrustumCulling/applet/index.html ViewFrustumCulling] examples (which handle multiple viewers) need Adam's [http://github.com/acsmith/napplet/downloads napplet library (>=0.3.5)] to run.

=24/04/2010 Release of *Proscene v-0.8.0*=

The main changes in this release respect to the previous one (v-0.7.1) are:

  * New *keyframes*' functionality through the !KeyFrameInterpolator class.
  * New handy set of examples, including [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/CameraInterpolation/applet/index.html CameraInterpolation], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/FrameInterpolation/applet/index.html FrameInterpolation], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/Luxo/applet/index.html Luxo], [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/PointUnderPixel/applet/index.html PointUnderPixel], and [http://disi.unal.edu.co/grupos/remixlab/local/projects/proscene-0.9.0/demos/ScreenDrawing/applet/index.html ScreenDrawing].
  * Code polishing and tighter integration with *Processing*, meaning that sketches using *proscene* should run even faster than before.

This version of *Proscene* has been developed and fully tested in *Processing-1.1* under x86_64 GNU/Linux (Kubuntu-9.10). However, it should properly work under Mac and Windows too (as some users have reported).